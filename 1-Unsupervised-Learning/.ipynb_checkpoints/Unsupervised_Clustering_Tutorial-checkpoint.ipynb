{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c8545d3-63e4-4ee1-8db8-62236976046b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#Let us first import necessary libararies\n",
    "import numpy as np\n",
    "import glob\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d31b3-79fa-416e-9bae-56de4afe8be3",
   "metadata": {},
   "source": [
    "## Data Conversion\r\n",
    "\r\n",
    "The lidar data from the KITTI dataset is in `.bin` format which is currently not an accepted format in Open3D, hence this is converted to its `.pcd` equivalent. This has already been done for you and is located in the DATA folder of the main repo. However, should you come to work with the KITTI dataset yourself, here is the code to convert `.bin` files to `.pcd`, courtesy of [this Gist](https://gist.github.com/HTLife/e8f1c4ff1737710e34258ef965b48344).\r\n",
    "\r\n",
    "However, this version has some errors, and thus, I have modified it for your convenience:\r\n",
    "\r\n",
    "```python\r\n",
    "def convert_kitti_bin_to_pcd(binFilePath, output_name):\r\n",
    "    size_float = 4\r\n",
    "    list_pcd = []\r\n",
    "    with open(binFilePath, \"rb\") as f:\r\n",
    "        byte = f.read(size_float * 4)\r\n",
    "        while byte:\r\n",
    "            x, y, z, intensity = struct.unpack(\"ffff\", byte)\r\n",
    "            list_pcd.append([x, y, z])\r\n",
    "            byte = f.read(size_float * 4)\r\n",
    "    np_pcd = np.asarray(list_pcd)\r\n",
    "    pcd = o3d.geometry.PointCloud()\r\n",
    "    pcd.points = o3d.utility.Vector3dVector(np_pcd)\r\n",
    "    o3d.io.write_point_cloud(output_name, pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7668cb12-e55e-4b6e-aae7-3bfe21078847",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "\n",
    "In this first part we will observe the 3D pointcloud data. Per the kitty dataset its format is x, y, z, and intensity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1691acd-3cf2-4f5a-a20f-c7fa0711e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../DATA/lidar_data\\\\0000000000.pcd', '../DATA/lidar_data\\\\0000000001.pcd', '../DATA/lidar_data\\\\0000000002.pcd']\n"
     ]
    }
   ],
   "source": [
    "#Lets first load the data\n",
    "lidar_data_path = \"../DATA/lidar_data/*.pcd\"\n",
    "lidar_file_names = sorted(glob.glob(lidar_data_path))\n",
    "print(lidar_file_names[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b31a72dc-bcfd-4d1a-87c9-93b1a0a281b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../DATA/lidar_data\\0000000000.pcd\n"
     ]
    }
   ],
   "source": [
    "#We only need to work with one let us use the first one\n",
    "lidar_file = lidar_file_names[0]\n",
    "print(lidar_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885dbd25-ecac-4436-8bbd-47dfc610ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read lidar file and create pointcloud data for vizualization\n",
    "point_cloud = o3d.io.read_point_cloud(lidar_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837957b-a6ca-4164-81aa-8420cbdcf8cb",
   "metadata": {},
   "source": [
    "Note: To visualized in open3d there is no need do as below, however this is was done to make the visualizer more asthetically pleasing. To simply visuzlize your point cloud all you need to do is\n",
    "\n",
    "```python\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1daaa216-9e7f-4074-abf0-8c33a6c48b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will create a function to visuzlize the object with some extra adjustments\n",
    "def visualize_cloud(obj_list):\n",
    "    \"\"\"\n",
    "    Function modifies the Open3D visualizer for better display. \n",
    "\n",
    "    Parameters:\n",
    "    obj_list (list): A list of objects to visualize this can be multiple point clouds, bounding box data, etc\n",
    "\n",
    "    Returns:\n",
    "    type: Void\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a visualizer object\n",
    "    viz = o3d.visualization.Visualizer()\n",
    "    viz.create_window()\n",
    "    \n",
    "    # Add each object to the vizualizer\n",
    "    for obj in obj_list:\n",
    "        viz.add_geometry(obj)\n",
    "    \n",
    "    #Set the background color to black\n",
    "    opt = viz.get_render_option()\n",
    "    opt.background_color = np.array([0, 0, 0])  # RGB values for black\n",
    "    \n",
    "    #Run the visualizer\n",
    "    viz.run()\n",
    "    viz.destroy_window()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba360d6-cca9-4510-b772-9658bdb200f1",
   "metadata": {},
   "source": [
    "Lets call the function the output will be rendered on a different window however its ouput is shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf23085-dced-436c-a306-bb3231900864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rememeber a list is expected\n",
    "visualize_cloud([point_cloud])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964dea47-9ce2-48da-8c86-145a9d638b71",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "![Point Cloud Visualization](../Doc_Images/UNSUPERVISED_DOC_IMAGES/output_1.png)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c845434e-bf2e-4602-9595-44b09e956ec9",
   "metadata": {},
   "source": [
    "In the center of the point cloud, a distinct circular pattern is evident. This pattern corresponds to the position of the LiDAR device. A closer examination of the point cloud's structure will provide further understanding of the data characteristics.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24af25b3-21b5-49df-bbd3-996ae31c599d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122595, 3)\n"
     ]
    }
   ],
   "source": [
    "#Lets convert the point cloud to a numpy array\n",
    "point_cloud_numpy = np.asarray(point_cloud.points)\n",
    "print(point_cloud_numpy.shape)\n",
    "del point_cloud_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a15da8-27db-42fd-99e8-c704f62fdb35",
   "metadata": {},
   "source": [
    "### Point Cloud Array Structure\r\n",
    "\r\n",
    "The array is structured as `(N, 3)`, where:\r\n",
    "\r\n",
    "- `N` represents the **total number of points** within the point cloud.\r\n",
    "- Each point is defined by a coordinate triplet `(x, y, z)`, which indicates:\r\n",
    "  - `x, y, z`: The spatial location of each point in meters.\r\n",
    "  - The origin for these coordinates is the LiDAR system lities.\r\n",
    "ilities.\r\n",
    "itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ece3f-062d-4b53-ae4c-148ed7fa39ed",
   "metadata": {},
   "source": [
    "### Additional LiDAR Data Dimensions\n",
    "\n",
    "In addition to the standard `x, y, z` coordinates, the type of LiDAR system used can provide a range of other data dimensions, including, but not limited to:\n",
    "\n",
    "- **Intensity**: This measures the reflectivity of surfaces, helping to differentiate materials based on how they reflect light.\n",
    "- **RGB Color Data**: Offers detailed color information of the scanned surfaces, useful for creating visually rich and accurate representations.\n",
    "- **Radial Velocity Data**: Available in some advanced LiDAR systems, this feature provides insights into the movement of objects or surfaces, adding a dynamic aspect to the data.\n",
    "\n",
    "These additional data dimensions significantly enrich the point cloud dataset, allowing for a more comprehensive analysis and enhanced visualization capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31be1c-3009-404f-9292-dfedbdfc76c2",
   "metadata": {},
   "source": [
    "# Plane Segmentation Using Open3D\r\n",
    "Open3D offers a comprehensive set of tools for 3D LiDAR point cloud processing, one of which is the plane segmentation feature. This feature employs the RANSAC (Random Sample Consensus) algorithm, a robust method known for its ability to identify and segregate outliers from a dataset. In the context of point clouds, this approach is slightly modified: the 'inliers', or points sharing common characteristics, are typically the ground points, which are often not the focus of our analysis. Consequently, the RANSAC algorithm plays a crucial role in preprocessing by isolating and removing these ground points.\r\n",
    "\r\n",
    "This preprocessing is key to concentrating on the objects of interest, leading to more efficient data processing and enhanced clustering capabilities due to the reduced computational burden.\r\n",
    "\r\n",
    "In our scenario, we have the `point_cloud` variable, an instance of the `PointCloud` class, equipped with the `segment_plane` method. This method is instrumental in excluding ground points and operates based on three parameters, as detailed in the Open3D documentation:\r\n",
    "\r\n",
    "1. `distance_threshold`: Defines the maximum distance a point can be from the estimated plane to be considered an inlier.\r\n",
    "2. `ransac_n`: Sets the number of points randomly selected for estimating a plane.\r\n",
    "3. `num_iterations`: Specifies the frequency of random plane sampling and evaluation.\r\n",
    "\r\n",
    "The `segment_plane` method outputs the plane's equation in the format `(a, b, c, d)`, conforming to the plane equation `ax + by + cz + d = 0`. This equation is pivotal in differentiating inliers from outliers. Moreover, the method returns a list of indices representing the inlier points, which is invaluable for further data analysis and processing.rocessing.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b4de582-7f7a-4139-93ca-aa452ff7f67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plane equation: -0.01x + 0.02y + 1.00z + 1.70 = 0\n"
     ]
    }
   ],
   "source": [
    "#Lets start with getting our inlier list and plane equation\n",
    "plane_model, inliers = point_cloud.segment_plane(distance_threshold=0.01,\n",
    "                                         ransac_n=3,\n",
    "                                         num_iterations=1000)\n",
    "[a, b, c, d] = plane_model\n",
    "print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b7b1c7-f6dd-4f4d-b77c-8893a043d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us visualize the inlier cloud. Remember inliers is a list of indexes of the points that are considered to be inliers by the algorithm\n",
    "inlier_cloud = point_cloud.select_by_index(inliers)\n",
    "#Let us paint these points green remember standard RGB is R, G, B\n",
    "inlier_cloud.paint_uniform_color([0, 1.0, 0])\n",
    "#Lets now visualize the point cloud\n",
    "visualize_cloud([inlier_cloud])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850de60-a731-4f1d-9ee9-f94b0b74d4cd",
   "metadata": {},
   "source": [
    "### Output (Inlier Cloud)\n",
    "\n",
    "\n",
    "![Point Cloud Visualization](../Doc_Images/UNSUPERVISED_DOC_IMAGES/output_2.png)\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ade302e-59d6-4bc4-8a27-81b18759ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us now visuzlie the outlier cloud or our point cloud of interest setting invert to true to flip indexes from inliers to outliers\n",
    "outlier_cloud = point_cloud.select_by_index(inliers, invert=True)\n",
    "#Let us paint these points red remember standard RGB is R, G, B\n",
    "outlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "#Lets now visualize the point cloud\n",
    "visualize_cloud([outlier_cloud])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1b0dc6-ce02-439e-bd93-4fbdfbb59b89",
   "metadata": {},
   "source": [
    "### Output (Outlier Cloud)\n",
    "\n",
    "\n",
    "![Point Cloud Visualization](../Doc_Images/UNSUPERVISED_DOC_IMAGES/output_3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ed7c29-a560-4f97-b7d3-6071980c9c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets visualize both\n",
    "visualize_cloud([inlier_cloud, outlier_cloud])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016dc8e9-eef7-419c-9289-0bfd56cc0f3d",
   "metadata": {},
   "source": [
    "### Output (Inlier + Outlier Cloud)\n",
    "![Point Cloud Visualization](../Doc_Images/UNSUPERVISED_DOC_IMAGES/output_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1990ac9-bd47-4327-ab4c-a409982e30cc",
   "metadata": {},
   "source": [
    "Observe that the segmentation of ground points was not entirely successful, indicating a need for further refinement in the RANSAC algorithm parameters. This adjustment is crucial for more accurate and effective separation of the ground points. \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f35b43f6-69a1-4ffb-aae4-28841c6dc86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets start with getting our inlier list we dont care about the plane equation\n",
    "#Let try to increase our distance threshold number of points for selecting a plane\n",
    "_, inliers = point_cloud.segment_plane(distance_threshold=0.11,\n",
    "                                         ransac_n=5,\n",
    "                                         num_iterations=1000)\n",
    "\n",
    "#Get inlier cloud\n",
    "inlier_cloud = point_cloud.select_by_index(inliers)\n",
    "#Let us paint these points green remember standard RGB is R, G, B\n",
    "inlier_cloud.paint_uniform_color([0, 1.0, 0])\n",
    "#Get outlier cloud\n",
    "outlier_cloud = point_cloud.select_by_index(inliers, invert=True)\n",
    "#Let us paint these points red remember standard RGB is R, G, B\n",
    "outlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "#Lets now visualize the point cloud\n",
    "visualize_cloud([inlier_cloud, outlier_cloud])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47259269-aeba-46c2-ae8e-f2d1e7e4daac",
   "metadata": {},
   "source": [
    "### Output (Inlier + Outlier Cloud)\n",
    "![Point Cloud Visualization](../Doc_Images/UNSUPERVISED_DOC_IMAGES/output_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc2507-d7b8-4b3a-8886-67d084564f68",
   "metadata": {},
   "source": [
    "As we can see there is better segmentation of the ground points. We will now explore clustering to groupu like point clouds together using DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0acb4c5-68d3-44bd-97b6-6422bc87496a",
   "metadata": {},
   "source": [
    "# DBSCAN Clustering\r\n",
    "\r\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is an effective clustering algorithm that groups points based on their spatial density. Key characteristics of DBSCAN include:\r\n",
    "\r\n",
    "- **Clustering Closely Packed Points**: It clusters points that are closely packed together, identifying points with many nearby neighbors.\r\n",
    "- **Identifying Noise**: Points in low-density regions, or those whose nearest neighbors are far away, are marked as noise.\r\n",
    "- **No Need to Predefine Cluster Count**: Unlike many clustering algorithms, DBSCAN does not require specifying the number of clusters.\r\n",
    "- **Handling Arbitrary Shapes**: DBSCAN can effectively handle clusters of arbitrary shapes.\r\n",
    "\r\n",
    "In our analysis, we have already performed plane segmentation to remove ground points. The resulting `outlier_cloud`, which is a `PointCloud` object in Open3D, will be used for DBSCAN clustering. Open3D implements this algorithm through the `cluster_dbscan` method, which requires two parameters:\r\n",
    "- `eps`: The maximum distance between two samples for one to be considered as in the neighborhood of the other.\r\n",
    "- `min_points`: The number of points required to form a dense region.\r\n",
    "\r\n",
    "The function returns `labels` for each point in the dataset, where the label `-1` indicates noise or outliers.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "195cbe1f-2902-4f34-9e83-345b9a34c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(outlier_cloud.cluster_dbscan(eps=0.5, min_points=20, print_progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a500eb64-d539-4c84-8aba-af2a59152183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,\n",
       "        12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,\n",
       "        25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,\n",
       "        38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,\n",
       "        51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,\n",
       "        64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
       "        77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,\n",
       "        90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
       "       103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
       "       116, 117, 118, 119, 120, 121], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc170597-9b4c-4bb2-831f-bdd88f873a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oulier cloud has 122 clusters\n"
     ]
    }
   ],
   "source": [
    "#Get max labels\n",
    "max_label = labels.max()\n",
    "print(f\"oulier cloud has {max_label + 1} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae748a6f-52e5-459a-bf77-1bd9191dafda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] [ViewControl] SetViewPoint() failed because window height and width are not set.\n"
     ]
    }
   ],
   "source": [
    "#We will now visuzlie and paint each individual cluster\n",
    "import matplotlib.pyplot as plt\n",
    "colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "# Set noise points to white\n",
    "colors[labels < 0] = 1\n",
    "outlier_cloud.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "#Call our function\n",
    "visualize_cloud([outlier_cloud])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437049f1-d2ad-4cee-95ff-f225b2c97372",
   "metadata": {},
   "source": [
    "### Output (Clustered Cloud with noise)\n",
    "![Point Cloud Visualization](../Doc_Images/UNSUPERVISED_DOC_IMAGES/output_6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e03fef4a-8b8d-43ed-bef7-eb177ee008d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets remove the ground points and visuzlize again\n",
    "#Lets get the indexes that are not noise\n",
    "not_noise_indexes = np.where(labels > 0)[0]\n",
    "#Get point cloud without noise using indexes\n",
    "outlier_cloud_without_noise = outlier_cloud.select_by_index(not_noise_indexes)\n",
    "#Subset labels as well\n",
    "labels_without_noise = labels[not_noise_indexes]\n",
    "#Create color map again\n",
    "colors = plt.get_cmap(\"tab20\")(labels_without_noise  / (max_label if max_label > 0 else 1))\n",
    "outlier_cloud_without_noise.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "#Call our function\n",
    "visualize_cloud([outlier_cloud_without_noise])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67111ab5-1bd9-4dd3-8445-f512c281924d",
   "metadata": {},
   "source": [
    "### Output (Clustered Cloud without noise)\n",
    "![Point Cloud Visualization](../Doc_Images/UNSUPERVISED_DOC_IMAGES/output_7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d01be-8964-4619-9109-1037a7b9e790",
   "metadata": {},
   "source": [
    "### Analyzing Clusters in the KITTI Dataset\n",
    "\n",
    "The utilization of unsupervised clustering techniques has enabled us to effectively distinguish distinct clusters within the KITTI dataset, such as vehicles and cyclists. The resulting visualizations can segregate these entities into separate clusters. However, it's noteworthy that the technique categorizes different objects within the same class as distinct clusters.\n",
    "\n",
    "The realm of 3D object detection and perception is vast, encompassing numerous applications. This demonstration represents only a single aspect of its extensive potential. Furthermore, the integration of 3D clustering with data fusion methods, particularly with imagery data, significantly enhances its efficacy in 3D object detection and perception analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8d8fc3-54b0-494b-9854-8b312e9780f8",
   "metadata": {},
   "source": [
    "# Voxel downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42f0156-3505-4cdb-b137-c4bc944f2ca5",
   "metadata": {},
   "source": [
    "In unsupervised clustering, significant computational resources are required, from employing RANSAC for ground point removal to utilizing clustering algorithms like DBSCAN. Voxel downsampling is an efficient technique to mitigate this by reducing the point cloud's size while retaining its overall structure. It works by dividing the 3D space into cubic units known as voxels and keeping only a representative point (either the centroid or average) for each voxel. The trade-off is clear: larger voxels mean more significant downsampling and a consequent loss of information. However, when applied correclty, voxel downsampling effectively decreases the number of points, thereby reducing the computational load for subsequent processing or algorithms. Open3D's `PointCloud` class conveniently includes a `voxel_down_sample` method, where `voxel_size` is its input parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b37c6ed4-2f0f-47b1-9764-8d7511aa2932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122595, 3)\n"
     ]
    }
   ],
   "source": [
    "#Let us first analayze the computational time it takes without downsampling\n",
    "import time\n",
    "#We already have the original point_cloud\n",
    "print(f\"{np.asarray(point_cloud.points).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d983b1f7-1941-49b9-b960-0ab51826a38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm Time without downsampling: 1.624253273010254\n"
     ]
    }
   ],
   "source": [
    "#Let us time the entire algorihtm\n",
    "start = time.time()\n",
    "#Remove ground points\n",
    "_, inliers = point_cloud.segment_plane(distance_threshold=0.11,\n",
    "                                         ransac_n=5,\n",
    "                                         num_iterations=1000)\n",
    "#Get outlier cloud\n",
    "outlier_cloud = point_cloud.select_by_index(inliers, invert=True)\n",
    "\n",
    "#Cluster cloud \n",
    "labels = np.array(outlier_cloud.cluster_dbscan(eps=0.5, min_points=20, print_progress=True))\n",
    "end = time.time()\n",
    "\n",
    "time_without_down_sampling = end - start\n",
    "\n",
    "print(f\"Algorithm Time without downsampling: {time_without_down_sampling}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4804f538-e96f-469f-8949-2f8d8e2f84e9",
   "metadata": {},
   "source": [
    "Lets now explore voxel downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c28059c6-6555-4e61-bcbd-c43ca7cbe952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 122595 || Final: 73179\n",
      "Perecent Retention: 59.69166768628411%\n"
     ]
    }
   ],
   "source": [
    "down_sampled_cloud = point_cloud.voxel_down_sample(voxel_size=0.08)\n",
    "#Initial number of points \n",
    "N_i = np.asarray(point_cloud.points).shape[0]\n",
    "#Final number of points\n",
    "N_f = np.asarray(down_sampled_cloud.points).shape[0]\n",
    "#Lets see how many points are left\n",
    "print(f\"Initial: {N_i} || Final: {N_f}\")\n",
    "print(f\"Perecent Retention: {(N_f/N_i)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f73a66-c366-4849-a35e-e1c12c774834",
   "metadata": {},
   "source": [
    "We are now left with only `60%` of the original points let us visualize this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed098b88-2e7d-466e-8483-cfdc3287a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_cloud([down_sampled_cloud])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51de485e-f6f0-4d05-868e-85912c9d24f4",
   "metadata": {},
   "source": [
    "### Output (Downsampled Cloud)\n",
    "![Point Cloud Visualization](../Doc_Images/UNSUPERVISED_DOC_IMAGES/output_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3620249-9015-462b-971c-7a2a742fa701",
   "metadata": {},
   "source": [
    "We can see here the cloud has been downsampled but still looks very full and complete without much loss of its original structure. \n",
    "\n",
    "Let us now see how much faster the overall pipeline runs when we apply voxel down sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d37d6947-951c-497d-af62-c6eb7b8c8e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm Time with downsampling: 0.48390746116638184\n"
     ]
    }
   ],
   "source": [
    "#Let us time the entire algorihtm\n",
    "start = time.time()\n",
    "\n",
    "#Down sample cloud must be included in the computational overhead\n",
    "down_sampled_cloud = point_cloud.voxel_down_sample(voxel_size=0.08)\n",
    "\n",
    "#Remove ground points\n",
    "_, inliers = down_sampled_cloud.segment_plane(distance_threshold=0.11,\n",
    "                                         ransac_n=5,\n",
    "                                         num_iterations=1000)\n",
    "#Get outlier cloud\n",
    "outlier_cloud = down_sampled_cloud.select_by_index(inliers, invert=True)\n",
    "\n",
    "#Cluster cloud \n",
    "labels = np.array(outlier_cloud.cluster_dbscan(eps=0.5, min_points=20, print_progress=True))\n",
    "end = time.time()\n",
    "\n",
    "time_with_down_sampling = end - start\n",
    "\n",
    "print(f\"Algorithm Time with downsampling: {time_with_down_sampling}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "077100a9-3d1e-4f48-ac47-09ce95baaedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Computational Speed up on CPU: 3.356536948397634\n"
     ]
    }
   ],
   "source": [
    "#Should\n",
    "print(f\"Overall Computational Speed up on CPU: {time_without_down_sampling/ time_with_down_sampling}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31930197-eb08-424b-b9ac-e410ecb6b6b8",
   "metadata": {},
   "source": [
    "We can see here we have obtained a 3.3 times computational speed up! but how does this affect our clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "70e86ff7-159c-432b-bb75-77267033855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oulier cloud has 92 clusters\n"
     ]
    }
   ],
   "source": [
    "max_label = labels.max()\n",
    "print(f\"oulier cloud has {max_label + 1} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "951f26cc-74b7-481f-9ebc-6b36f6fe7d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets get the indexes that are not noise\n",
    "not_noise_indexes = np.where(labels > 0)[0]\n",
    "#Get point cloud without noise using indexes\n",
    "outlier_cloud_without_noise = outlier_cloud.select_by_index(not_noise_indexes)\n",
    "#Subset labels as well\n",
    "labels_without_noise = labels[not_noise_indexes]\n",
    "#Create color map again\n",
    "colors = plt.get_cmap(\"tab20\")(labels_without_noise  / (max_label if max_label > 0 else 1))\n",
    "outlier_cloud_without_noise.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "#Call our function\n",
    "visualize_cloud([outlier_cloud_without_noise])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb95da05-de89-4792-a223-ecd6bcb994ba",
   "metadata": {},
   "source": [
    "### Output (Clustered Downsampled Cloud)\n",
    "![Point Cloud Visualization](../Doc_Images/UNSUPERVISED_DOC_IMAGES/output_9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69beae8-aef9-4e28-b16d-5fde8e0fdfae",
   "metadata": {},
   "source": [
    "### Impact of Voxel Downsampling on Clustering Efficiency\r\n",
    "\r\n",
    "Qualitatively, it's evident that voxel downsampling has enhanced the efficiency of our clustering algorithm. While currently we are clustering based on `x, y, z` coordinates, the inclusion of additional features such as RGB values, intensity, or other metrics from advanced LiDAR systems could further improve clustering results. This additional data can provide more context and detail, leading to better segmentation and identification of objects.\r\n",
    "\r\n",
    "Voxel downsampling plays a crucial role in 3D object detection algorithms, particularly when utilizing LiDAR data. Its significance is even more pronounced in applications requiring real-time responses, such as autonomous driving vehicles. By reducing the data size without losing critical structural information, voxel downsampling ensures that the algorithms can run swiftly and efficiently, a key requirement for timely decision-making in dynamic environments.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b53fe2-a57b-47d9-8b0b-8801cce046f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
